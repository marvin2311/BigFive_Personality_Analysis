{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einlesen und erste Betrachtung des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#loading data\n",
    "data = pd.read_csv(\"data-final.csv\", sep=\"\\t\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenvorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untersuchung + Bereinigen fehlende Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looking for missing values\n",
    "data[columns].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of the dataset and drop the missing values\n",
    "df = data.copy()\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing the length of both datasets\n",
    "\n",
    "print(len(data))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result of the comparison: nearly 3000 objects were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if there are any missing values left\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einteilung der Aussagen in ihre Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group questions with column name \n",
    "\n",
    "ext_questions = {'EXT1' : 'I am the life of the party',\n",
    "                 'EXT2' : 'I dont talk a lot',\n",
    "                 'EXT3' : 'I feel comfortable around people',\n",
    "                 'EXT4' : 'I keep in the background',\n",
    "                 'EXT5' : 'I start conversations',\n",
    "                 'EXT6' : 'I have little to say',\n",
    "                 'EXT7' : 'I talk to a lot of different people at parties',\n",
    "                 'EXT8' : 'I dont like to draw attention to myself',\n",
    "                 'EXT9' : 'I dont mind being the center of attention',\n",
    "                 'EXT10': 'I am quiet around strangers'}\n",
    "\n",
    "est_questions = {'EST1' : 'I get stressed out easily',\n",
    "                 'EST2' : 'I am relaxed most of the time',\n",
    "                 'EST3' : 'I worry about things',\n",
    "                 'EST4' : 'I seldom feel blue',\n",
    "                 'EST5' : 'I am easily disturbed',\n",
    "                 'EST6' : 'I get upset easily',\n",
    "                 'EST7' : 'I change my mood a lot',\n",
    "                 'EST8' : 'I have frequent mood swings',\n",
    "                 'EST9' : 'I get irritated easily',\n",
    "                 'EST10': 'I often feel blue'}\n",
    "\n",
    "agr_questions = {'AGR1' : 'I feel little concern for others',\n",
    "                 'AGR2' : 'I am interested in people',\n",
    "                 'AGR3' : 'I insult people',\n",
    "                 'AGR4' : 'I sympathize with others feelings',\n",
    "                 'AGR5' : 'I am not interested in other peoples problems',\n",
    "                 'AGR6' : 'I have a soft heart',\n",
    "                 'AGR7' : 'I am not really interested in others',\n",
    "                 'AGR8' : 'I take time out for others',\n",
    "                 'AGR9' : 'I feel others emotions',\n",
    "                 'AGR10': 'I make people feel at ease'}\n",
    "\n",
    "csn_questions = {'CSN1' : 'I am always prepared',\n",
    "                 'CSN2' : 'I leave my belongings around',\n",
    "                 'CSN3' : 'I pay attention to details',\n",
    "                 'CSN4' : 'I make a mess of things',\n",
    "                 'CSN5' : 'I get chores done right away',\n",
    "                 'CSN6' : 'I often forget to put things back in their proper place',\n",
    "                 'CSN7' : 'I like order',\n",
    "                 'CSN8' : 'I shirk my duties',\n",
    "                 'CSN9' : 'I follow a schedule',\n",
    "                 'CSN10' : 'I am exacting in my work'}\n",
    "\n",
    "opn_questions = {'OPN1' : 'I have a rich vocabulary',\n",
    "                 'OPN2' : 'I have difficulty understanding abstract ideas',\n",
    "                 'OPN3' : 'I have a vivid imagination',\n",
    "                 'OPN4' : 'I am not interested in abstract ideas',\n",
    "                 'OPN5' : 'I have excellent ideas',\n",
    "                 'OPN6' : 'I do not have a good imagination',\n",
    "                 'OPN7' : 'I am quick to understand things',\n",
    "                 'OPN8' : 'I use difficult words',\n",
    "                 'OPN9' : 'I spend time reflecting on things',\n",
    "                 'OPN10': 'I am full of ideas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group columns for every type\n",
    "\n",
    "EXT_col = [col for col in data if col.startswith('EXT')]\n",
    "EST_col = [col for col in data if col.startswith('EST')]\n",
    "AGR_col = [col for col in data if col.startswith('AGR')]\n",
    "CSN_col = [col for col in data if col.startswith('CSN')]\n",
    "OPN_col = [col for col in data if col.startswith('OPN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group positively and negatively keyed questions\n",
    "\n",
    "positiv_questions = ['EXT1', 'EXT3', 'EXT5', 'EXT7', 'EXT9',\n",
    "                    'EST1', 'EST3', 'EST5', 'EST6', 'EST7', \n",
    "                    'EST8', 'EST9', 'EST10',\n",
    "                    'AGR2', 'AGR4', 'AGR6', 'AGR8', 'AGR9', 'AGR10',\n",
    "                    'CSN1', 'CSN3', 'CSN5', 'CSN7', 'CSN9', 'CSN10', \n",
    "                    'OPN1', 'OPN3', 'OPN5', 'OPN7', 'OPN8', 'OPN9', \n",
    "                    'OPN10']\n",
    "\n",
    "negative_questions = ['EXT2', 'EXT4', 'EXT6', 'EXT8', 'EXT10',\n",
    "                    'EST2', 'EST4',\n",
    "                    'AGR1', 'AGR3', 'AGR5', 'AGR7', \n",
    "                    'CSN2', 'CSN4', 'CSN6', 'CSN8', \n",
    "                    'OPN2', 'OPN4', 'OPN6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reverse values of negative questions\n",
    "\n",
    "df.loc[:, negative_questions] = 6 - df.loc[:, negative_questions]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personality Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# new data frame that just includes the answers on the questions\n",
    "df_model = df[df.columns.tolist()[:50]]\n",
    "\n",
    "# creating a model and fitting it with the data \n",
    "kmeans = KMeans(n_clusters=5)\n",
    "km_fitted = kmeans.fit(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the column cluster to the data frame\n",
    "\n",
    "df_model.loc[:, 'Cluster'] = km_fitted.labels_\n",
    "df_model.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the rows for every cluster\n",
    "\n",
    "df_model.Cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize the amount in a countplot\n",
    "\n",
    "sns.countplot(data=df_model, x='Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_model['Country_cat'] = df['country']\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(df_model['Country_cat'])\n",
    "df_model.loc[:, 'Country_num'] = le.transform(df_model['Country_cat'])\n",
    "\n",
    "df_model.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionsreduktion & Vergleich der angefertigten Clustern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new data frame to reduce the dimensions for every catagory\n",
    "col_list = list(df_model)\n",
    "ext = col_list[0:10]\n",
    "est = col_list[10:20]\n",
    "agr = col_list[20:30]\n",
    "csn = col_list[30:40]\n",
    "opn = col_list[40:50]\n",
    "\n",
    "df_sums = pd.DataFrame()\n",
    "df_sums['extroversion'] = df_model[ext].sum(axis=1)/10\n",
    "df_sums['neurotic'] = df_model[est].sum(axis=1)/10\n",
    "df_sums['agreeable'] = df_model[agr].sum(axis=1)/10\n",
    "df_sums['conscientious'] = df_model[csn].sum(axis=1)/10\n",
    "df_sums['open'] = df_model[opn].sum(axis=1)/10\n",
    "df_sums['cluster'] = df_model['Cluster'] #Target-Größe\n",
    "\n",
    "# displaying the mean for every catagory in each cluster\n",
    "df_sums.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 0 sehr introvertiert (wenig extrovertiert) und neurotisch --> leichte negative Korrelation\n",
    "\n",
    "Wirkliche Basistypen nicht rauszufiltern, recht ähnlich bei Open - auch sonst alles innerhalb von 1.0 Abweichung nur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms for every category\n",
    "\n",
    "for col in df_sums.columns:\n",
    "    if col == 'cluster':\n",
    "        continue\n",
    "    print(col.upper())\n",
    "    sns.distplot(df_sums[col])\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating heatmaps to visualize the correlations between each category (using 3 different methods)\n",
    "\n",
    "meths = ['pearson', 'spearman', 'kendall']\n",
    "\n",
    "for meth in meths:\n",
    "    print(meth.upper())\n",
    "    corrm= df_sums.drop(columns='cluster').corr(method=meth)\n",
    "    sns.heatmap(corrm, annot=True)\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total time answering the questions (in minutes) \n",
    "df_sums['total_time_min'] = round(df[df.columns.tolist()[50:100]].sum(axis=1)/60000, 2)\n",
    "df_sums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting pairplots of each catagory (be aware that the calculation takes a lot of time!!!)\n",
    "\n",
    "sns.pairplot(df_sums.drop(columns='total_time_min'), hue=\"cluster\", palette=\"bright\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:  Do the subjects' statements depend on the time of day?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die Studie in den USA erhoben wurde und die dortige Uhrzeit für alle Probanden übernommen wurde, reduziert sich die Analyse auf US-Bürger. Dazu wird ein Datensatz nur mit US-Amerikanern benutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to get only US citizens and checking the length\n",
    "US = df['country'] == 'US'\n",
    "Dataset_USA = df[US]\n",
    "Dataset_USA = Dataset_USA[Dataset_USA.columns.tolist()[:50]]\n",
    "Dataset_USA['dateload'] = df['dateload']\n",
    "\n",
    "#print(len(Dataset_USA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a column for the time of the day, the survey was uploaded\n",
    "\n",
    "Dataset_USA['time'] = Dataset_USA.dateload.str[11:13].astype(int)\n",
    "Dataset_USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the quantity of every hour\n",
    "sns.countplot(data=Dataset_USA, x=Dataset_USA['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering the new time column in the categories 'morning', 'noon', 'evening', 'night'\n",
    "\n",
    "\n",
    "intervals = [0,6,12,18,24]\n",
    "daytime_categories = ['morning', 'noon', 'evening', 'night']\n",
    "\n",
    "Dataset_USA['daytime'] = pd.cut(x= Dataset_USA['time'], bins = intervals, labels = daytime_categories, include_lowest = True)\n",
    "Dataset_USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the different categories in daytime\n",
    "sns.countplot(data = Dataset_USA, x = Dataset_USA['daytime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating variables for each category in daytime\n",
    "morning = Dataset_USA['daytime'] == 'morning'\n",
    "noon = Dataset_USA['daytime'] == 'noon'\n",
    "evening = Dataset_USA['daytime'] == 'evening'\n",
    "night = Dataset_USA['daytime'] == 'night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking up the dataset for the morning category\n",
    "Dataset_USA[morning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#looking up the mean values of morning category\n",
    "Dataset_USA[morning].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the mean value of every daytime category in a list\n",
    "mean_list_morning = list(Dataset_USA[morning].mean())\n",
    "mean_list_noon = list(Dataset_USA[noon].mean())\n",
    "mean_list_evening = list(Dataset_USA[evening].mean())\n",
    "mean_list_night = list(Dataset_USA[night].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a new USA data frame to reduce the dimensions and compare the answers in relation to the daytime\n",
    "col_list = list(Dataset_USA)\n",
    "ext = col_list[0:10]\n",
    "est = col_list[10:20]\n",
    "agr = col_list[20:30]\n",
    "csn = col_list[30:40]\n",
    "opn = col_list[40:50]\n",
    "\n",
    "df_sums_usa = pd.DataFrame()\n",
    "df_sums_usa['extroversion'] = Dataset_USA[ext].sum(axis=1)/10\n",
    "df_sums_usa['neurotic'] = Dataset_USA[est].sum(axis=1)/10\n",
    "df_sums_usa['agreeable'] = Dataset_USA[agr].sum(axis=1)/10\n",
    "df_sums_usa['conscientious'] = Dataset_USA[csn].sum(axis=1)/10\n",
    "df_sums_usa['open'] = Dataset_USA[opn].sum(axis=1)/10\n",
    "df_sums_usa['daytime'] = Dataset_USA['daytime']\n",
    "\n",
    "# displaying the mean for every catagory in each cluster\n",
    "df_sums_usa.groupby('daytime').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: The answers of the americans who participated in the survey do not differ on different daytimes! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the personalities around the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_countries = pd.DataFrame(df['country'].value_counts())\n",
    "representive_countries = count_countries[count_countries['country'] >= 1000]\n",
    "representive_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a newdata frame to reduce the dimensions and compare the statements of the countrys\n",
    "col_list = list(df)\n",
    "ext = col_list[0:10]\n",
    "est = col_list[10:20]\n",
    "agr = col_list[20:30]\n",
    "csn = col_list[30:40]\n",
    "opn = col_list[40:50]\n",
    "\n",
    "df_sums_world = pd.DataFrame()\n",
    "df_sums_world['extroversion'] = df[ext].sum(axis=1)/10\n",
    "df_sums_world['neurotic'] = df[est].sum(axis=1)/10\n",
    "df_sums_world['agreeable'] = df[agr].sum(axis=1)/10\n",
    "df_sums_world['conscientious'] = df[csn].sum(axis=1)/10\n",
    "df_sums_world['open'] = df[opn].sum(axis=1)/10\n",
    "df_sums_world['country'] = df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all rows from df_sums_world that have les than 1000 participants --> takes very long!!\n",
    "for country in df_sums_world['country']:\n",
    "    if country in representive_countries:\n",
    "        pass\n",
    "    else:\n",
    "        df_sums_world = df_sums_world.drop(df_sums_world[(df_sums_world.country == country)].index)\n",
    "\n",
    "df_sums_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the mean for every catagory in each country\n",
    "country_means_per_category = df_sums_world.groupby('country').mean() \n",
    "country_means_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting an overview about the range/highs/lows in the columns and examine the countries with max-min values\n",
    "print(country_means_per_category.loc[country_means_per_category['extroversion'].idxmax()])\n",
    "print()\n",
    "print(country_means_per_category.loc[country_means_per_category['extroversion'].idxmin()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most extroversion:**\n",
    "\n",
    "**Most interversion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(country_means_per_category.loc[country_means_per_category['neurotic'].idxmax()])\n",
    "print(country_means_per_category.loc[country_means_per_category['neurotic'].idxmin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most neurotic:**\n",
    "\n",
    "**least neurotic :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(country_means_per_category.loc[country_means_per_category['agreeable'].idxmax()])\n",
    "print(country_means_per_category.loc[country_means_per_category['agreeable'].idxmin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most agreeable:**\n",
    "\n",
    "**least agreeable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country_means_per_category.loc[country_means_per_category['conscientious'].idxmax()])\n",
    "print(country_means_per_category.loc[country_means_per_category['conscientious'].idxmin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most conscientious:**\n",
    "\n",
    "**least conscientious:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(country_means_per_category.loc[country_means_per_category['open'].idxmax()])\n",
    "print(country_means_per_category.loc[country_means_per_category['open'].idxmin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most open: Mali**\n",
    "\n",
    "**least open: Bonaire, Sint Eustatius und Saba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot countries with more than 10.000 participants\n",
    "\n",
    "countries = pd.DataFrame(df['country'].value_counts())\n",
    "countries_10k = countries[countries['country'] >= 10000]\n",
    "\n",
    "sns.barplot(data=countries_10k, x=countries_10k.index, y='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking at the means of germany\n",
    "countries = pd.DataFrame(df['country'].value_counts())\n",
    "countries_10k = countries[countries['country'] >= 10000]\n",
    "\n",
    "germany = df_sums_world['country'] == 'DE'\n",
    "df_sums_world[germany].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deutschland sehr ausgeglichene Nation --> Überall circa im Durchschnitt, etwas weniger gewissenhaft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mean comparison of those countries that had more than 10.000 participants\n",
    "country_means_per_category[df['country'].value_counts() >= 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating heatmaps to visualize the correlations between each category (using 3 different methods)\n",
    "\n",
    "meths = ['pearson', 'spearman', 'kendall']\n",
    "\n",
    "for meth in meths:\n",
    "    print(meth.upper())\n",
    "    corrm= country_means_per_category[df['country'].value_counts() >= 10000].corr(method=meth)\n",
    "    sns.heatmap(corrm, annot=True)\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** There are only narrow differences between the mean answers of the examined countries (10.000+ participants). Therefore, also the nationality of the participants is not critical for the given statements.\n",
    "\n",
    "Interesting could be a view on the correlation matrix. In the smaller Dataset country_mean_per_country are many strong (positive as well as negative) correlations betwenn the columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location of every participant in the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot location of people who attend the survey\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# get coordinates\n",
    "\n",
    "lat_cor = pd.to_numeric(df['lat_appx_lots_of_err'], errors='coerce')\n",
    "long_cor = pd.to_numeric(df['long_appx_lots_of_err'], errors='coerce')\n",
    "\n",
    "# transform coordinates to use them with geopandas, load geopandas world map\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(long_cor, lat_cor)]\n",
    "gdf = GeoDataFrame(df, geometry=geometry)\n",
    "geo_file = gpd.datasets.get_path('naturalearth_lowres')\n",
    "\n",
    "# create the plot \n",
    "\n",
    "world = gpd.read_file(geo_file)\n",
    "world_ax = world.drop(159).plot(figsize=(60, 10))\n",
    "gdf.plot(ax=world_ax, marker='x', color='green', markersize=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
